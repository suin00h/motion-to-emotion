{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca0814f",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb39c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d6a70",
   "metadata": {},
   "source": [
    "## Label data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('L_SIT/20201030_dog-sit-000273.mp4.json', encoding='utf-8') as f:\n",
    "  label_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41144f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_sample.keys())\n",
    "\n",
    "name, meta, anno = label_sample.values()\n",
    "print(f'''\n",
    "video name: {name}\n",
    "seq #     : {meta['seq']}\n",
    "action    : {meta['action']}\n",
    "emotion   : {meta['inspect']['emotion']}\n",
    "height    : {meta['height']}\n",
    "width     : {meta['width']}\n",
    "frames    : {len(anno)}\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno[0]['bounding_box']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6c84c",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72462662",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = [ 'BODYLOWER', 'SIT' ]\n",
    "emo_list = [ '공격성', '공포', '불안/슬픔', '편안/안정', '행복/즐거움', '화남/불쾌' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1becb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# label.csv\n",
    "#-------------------------------------------------------------------------\n",
    "# filename : '{seq}_{frame}.jpg'\n",
    "# seq      : sequence ID number; representing same video source\n",
    "# frame_idx: frame ID number; 0, 1, 2, ...\n",
    "# action   : action class number\n",
    "# emotion  : emotion class number\n",
    "# bbox     : bounding box; (x1, y1, x2, y2); starting/ending point\n",
    "# keypoints: keypoints; [(x, y, v), ... ], v for visibility\n",
    "##########################################################################\n",
    "l = open('label.csv', 'w', newline='')\n",
    "lr = csv.writer(l)\n",
    "lr.writerow(['file_name', 'seq', 'frame_idx', 'action', 'emotion', 'bbox', 'keypoints'])\n",
    "\n",
    "# directory for training images\n",
    "try:\n",
    "    os.mkdir('train')\n",
    "except:\n",
    "    ...\n",
    "\n",
    "# error log\n",
    "err = open('error.csv', 'w', newline='')\n",
    "er = csv.writer(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4335d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each Action folder\n",
    "for i, act in enumerate(action_list):\n",
    "\n",
    "    # for each video\n",
    "    for video in tqdm(os.listdir(f'O_{act}'), desc=f'{act:10}'):\n",
    "        if video == '.ipynb_checkpoints':\n",
    "            continue\n",
    "\n",
    "        # extract informations from label file\n",
    "        try:\n",
    "            with open(f'L_{act}/{video}.json', 'r', encoding='utf-8') as f:\n",
    "                label = json.load(f)\n",
    "                _, meta, anno = label.values()\n",
    "                seq = int(meta['seq'])\n",
    "                emotion = emo_list.index(meta['inspect']['emotion'])\n",
    "        except Exception as e:\n",
    "            er.writerow([e])\n",
    "            continue\n",
    "\n",
    "        # for each frame\n",
    "        for j, frame_name in enumerate(natsorted(os.listdir(f'O_{act}/{video}'))):\n",
    "            # find annotation index\n",
    "            temp = re.split('[_.]', frame_name)\n",
    "            N_fr = int(temp[1])\n",
    "            N_ts = int(temp[3])\n",
    "            img_name = f'{seq}_{N_fr}.jpg'\n",
    "\n",
    "            # get annotation data\n",
    "            keys = dict()\n",
    "            bbox = dict()\n",
    "            for frame in anno:\n",
    "                if frame['frame_number'] == N_fr and frame['timestamp'] == N_ts:\n",
    "                    keys = frame['keypoints']\n",
    "                    bbox = frame['bounding_box']\n",
    "                    break\n",
    "            \n",
    "            # bounding box\n",
    "            x1, y1, w, h = bbox.values()\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "\n",
    "            # keypoints\n",
    "            keylist = []\n",
    "            for key in keys.values():\n",
    "                keylist.append([key['x'], key['y'], 1] if type(key) == dict else [0, 0, 0])\n",
    "\n",
    "            # copy images to new directory and rename\n",
    "            shutil.copyfile(f'O_{act}/{video}/{frame_name}', f'train/{img_name}')\n",
    "\n",
    "            # label.csv logging\n",
    "            lr.writerow([img_name, seq, j, i, emotion, [x1, y1, x2, y2], keylist])\n",
    "l.close()\n",
    "err.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
