{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca0814f",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb39c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from utils.data import to_tensor, norm_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d6a70",
   "metadata": {},
   "source": [
    "## 2. Label Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1436c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Training/L_SIT/20201030_dog-sit-000273.mp4.json', encoding='utf-8') as f:\n",
    "    label_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41144f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['file_video', 'metadata', 'annotations'])\n",
      "\n",
      "video name: dog-sit-000273.mp4\n",
      "seq #     : 273\n",
      "action    : 앉기\n",
      "emotion   : 행복/즐거움\n",
      "height    : 1280\n",
      "width     : 720\n",
      "frames    : 86\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "print(label_sample.keys())\n",
    "\n",
    "name, meta, anno = label_sample.values()\n",
    "print(f'''\n",
    "video name: {name}\n",
    "seq #     : {meta['seq']}\n",
    "action    : {meta['action']}\n",
    "emotion   : {meta['inspect']['emotion']}\n",
    "height    : {meta['height']}\n",
    "width     : {meta['width']}\n",
    "frames    : {len(anno)}\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c359a36e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 6, 'y': 311, 'width': 592, 'height': 766}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno[0]['bounding_box']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6c84c",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing\n",
    "    - Train: 39537\n",
    "    - Val  : 2474\n",
    "    - Test : 2475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72462662",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = [ 'BODYLOWER', 'BODYSCRATCH', 'BODYSHAKE', 'FEETUP', 'FOOTUP', 'HEADING',\n",
    "                'LYING', 'MOUNTING', 'SIT', 'TAILING', 'TAILLOW', 'TURN', 'WALKRUN' ]\n",
    "emo_list = [ '공격성', '공포', '불안/슬픔', '편안/안정', '행복/즐거움', '화남/불쾌' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d85d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# label.csv\n",
    "#-------------------------------------------------------------------------\n",
    "# filename : '{seq}_{frame}.jpg'\n",
    "# seq      : sequence ID number; representing same video source\n",
    "# frame_idx: frame ID number; 0, 1, 2, ...\n",
    "# action   : action class number\n",
    "# emotion  : emotion class number\n",
    "# bbox     : bounding box; (x1, y1, x2, y2); starting/ending point\n",
    "# keypoints: keypoints; [(x, y, v), ... ], v for visibility\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee4335d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BODYLOWER  : 100%|█████████████████████████████████████████████████████████████████| 6392/6392 [00:59<00:00, 107.25it/s]\n",
      "BODYSCRATCH: 100%|█████████████████████████████████████████████████████████████████| 1228/1228 [00:18<00:00, 67.40it/s]\n",
      "BODYSHAKE  : 100%|█████████████████████████████████████████████████████████████████| 1327/1327 [00:18<00:00, 70.16it/s]\n",
      "FEETUP     : 100%|█████████████████████████████████████████████████████████████████| 2748/2748 [00:38<00:00, 70.85it/s]\n",
      "FOOTUP     : 100%|█████████████████████████████████████████████████████████████████| 4154/4154 [00:44<00:00, 67.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    source = ['Training', 'Validation'][i]\n",
    "    target = ['train', 'val'][i]\n",
    "    \n",
    "    label_log = open(os.path.join(target, 'label.csv'), 'w', newline='')\n",
    "    lr = csv.writer(label_log)\n",
    "    lr.writerow(['file_name', 'seq', 'frame_idx', 'action', 'emotion', 'bbox', 'keypoints'])\n",
    "    \n",
    "    error_log = open(os.path.join(target, 'error.csv'), 'w', newline='')\n",
    "    er = csv.writer(error_log)\n",
    "    \n",
    "    # for each Action folder\n",
    "    for i, act in enumerate(action_list):\n",
    "        path_label = os.path.join(source, f'L_{act}')\n",
    "        path_origin= os.path.join(source, f'O_{act}')\n",
    "\n",
    "        # for each video\n",
    "        for video in tqdm(os.listdir(path_origin), desc=f'{act:10}'):\n",
    "            if video == '.ipynb_checkpoints':\n",
    "                continue\n",
    "\n",
    "            # extract informations from label file\n",
    "            try:\n",
    "                with open(f'{path_label}/{video}.json', 'r', encoding='utf-8') as f:\n",
    "                    label = json.load(f)\n",
    "                    _, meta, anno = label.values()\n",
    "                    seq = int(meta['seq'])\n",
    "                    emotion = emo_list.index(meta['inspect']['emotion'])\n",
    "            except Exception as e:\n",
    "                er.writerow([e])\n",
    "                continue\n",
    "\n",
    "            # for each frame\n",
    "            for j, frame_name in enumerate(natsorted(os.listdir(f'{path_origin}/{video}'))):\n",
    "                # find annotation index\n",
    "                temp = re.split('[_.]', frame_name)\n",
    "                N_fr = int(temp[1])\n",
    "                N_ts = int(temp[3])\n",
    "                img_name = f'{seq}_{N_fr}.jpg'\n",
    "\n",
    "                # get annotation data\n",
    "                keys = dict()\n",
    "                bbox = dict()\n",
    "                for frame in anno:\n",
    "                    if frame['frame_number'] == N_fr and frame['timestamp'] == N_ts:\n",
    "                        keys = frame['keypoints']\n",
    "                        bbox = frame['bounding_box']\n",
    "                        break\n",
    "\n",
    "                # bounding box\n",
    "                x1, y1, w, h = bbox.values()\n",
    "                x2 = x1 + w\n",
    "                y2 = y1 + h\n",
    "\n",
    "                # keypoints\n",
    "                keylist = []\n",
    "                for key in keys.values():\n",
    "                    keylist.append([key['x'], key['y'], 1] if type(key) == dict else [0, 0, 0])\n",
    "\n",
    "                # copy images to new directory and rename\n",
    "                shutil.move(f'{path_origin}/{video}/{frame_name}', f'{target}/{img_name}')\n",
    "\n",
    "                # label.csv logging\n",
    "                lr.writerow([img_name, seq, j, i, emotion, [x1, y1, x2, y2], keylist])\n",
    "    label_log.close()\n",
    "    error_log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e8ea6",
   "metadata": {},
   "source": [
    "## 4. Label Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dacb5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>seq</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>action</th>\n",
       "      <th>emotion</th>\n",
       "      <th>bbox</th>\n",
       "      <th>keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28_0.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[145, 377, 540, 852]</td>\n",
       "      <td>[[326, 583, 1], [337, 498, 1], [356, 614, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28_12.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[154, 383, 540, 848]</td>\n",
       "      <td>[[325, 590, 1], [337, 498, 1], [356, 614, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28_102.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[137, 394, 524, 855]</td>\n",
       "      <td>[[317, 589, 1], [326, 492, 1], [344, 620, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28_108.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[137, 394, 524, 861]</td>\n",
       "      <td>[[317, 589, 1], [326, 492, 1], [344, 620, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28_114.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[132, 394, 524, 861]</td>\n",
       "      <td>[[313, 588, 1], [323, 492, 1], [344, 620, 1], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name  seq  frame_idx  action  emotion                  bbox  \\\n",
       "0    28_0.jpg   28          0       0        3  [145, 377, 540, 852]   \n",
       "1   28_12.jpg   28          1       0        3  [154, 383, 540, 848]   \n",
       "2  28_102.jpg   28          2       0        3  [137, 394, 524, 855]   \n",
       "3  28_108.jpg   28          3       0        3  [137, 394, 524, 861]   \n",
       "4  28_114.jpg   28          4       0        3  [132, 394, 524, 861]   \n",
       "\n",
       "                                           keypoints  \n",
       "0  [[326, 583, 1], [337, 498, 1], [356, 614, 1], ...  \n",
       "1  [[325, 590, 1], [337, 498, 1], [356, 614, 1], ...  \n",
       "2  [[317, 589, 1], [326, 492, 1], [344, 620, 1], ...  \n",
       "3  [[317, 589, 1], [326, 492, 1], [344, 620, 1], ...  \n",
       "4  [[313, 588, 1], [323, 492, 1], [344, 620, 1], ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train = pd.read_csv('data/train/label.csv')\n",
    "label_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ecaebc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 39532/39532 [04:30<00:00, 145.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>emotion</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[tensor(0.4582, dtype=torch.float64), tensor...</td>\n",
       "      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[tensor(0.4794, dtype=torch.float64), tensor...</td>\n",
       "      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[tensor(0.4735, dtype=torch.float64), tensor...</td>\n",
       "      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              action  \\\n",
       "0  [[[tensor(0.4582, dtype=torch.float64), tensor...   \n",
       "1  [[[tensor(0.4794, dtype=torch.float64), tensor...   \n",
       "2  [[[tensor(0.4735, dtype=torch.float64), tensor...   \n",
       "\n",
       "                                             emotion  \\\n",
       "0  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...   \n",
       "1  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...   \n",
       "2  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...   \n",
       "\n",
       "                                                keys  \n",
       "0  [[tensor(0.), tensor(0.), tensor(0.), tensor(1...  \n",
       "1  [[tensor(0.), tensor(0.), tensor(0.), tensor(1...  \n",
       "2  [[tensor(0.), tensor(0.), tensor(0.), tensor(1...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label_train = pd.DataFrame(columns=['action', 'emotion', 'keys'])\n",
    "\n",
    "for i, s in enumerate(tqdm(label_train['seq'].unique())):\n",
    "    df = label_train[label_train['seq']==s]\n",
    "    \n",
    "    bbox = to_tensor(df['bbox'])\n",
    "    keys = to_tensor(df['keypoints'])\n",
    "    keys = norm_keys(bbox, keys)\n",
    "    \n",
    "    action, emotion = df[['action', 'emotion']].iloc[0]\n",
    "    action = F.one_hot(torch.tensor([action]), num_action).float()\n",
    "    emotion = F.one_hot(torch.tensor([emotion]), num_emotion).float()\n",
    "    \n",
    "    new_label_train.loc[i] = [keys, action, emotion]\n",
    "    \n",
    "new_label_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec03611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4949/4949 [02:52<00:00, 28.64it/s]\n"
     ]
    }
   ],
   "source": [
    "label_val = pd.read_csv('data/val/label.csv')\n",
    "new_label_val = pd.DataFrame(columns=['action', 'emotion', 'keys'])\n",
    "\n",
    "for i, s in enumerate(tqdm(label_val['seq'].unique())):\n",
    "    df = label_val[label_val['seq']==s]\n",
    "    \n",
    "    bbox = to_tensor(df['bbox'])\n",
    "    keys = to_tensor(df['keypoints'])\n",
    "    keys = norm_keys(bbox, keys)\n",
    "    \n",
    "    action, emotion = df[['action', 'emotion']].iloc[0]\n",
    "    action = F.one_hot(torch.tensor([action]), num_action).float()\n",
    "    emotion = F.one_hot(torch.tensor([emotion]), num_emotion).float()\n",
    "    \n",
    "    new_label_val.loc[i] = [keys, action, emotion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bee88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_train.to_pickle('data/key_label_train')\n",
    "new_label_val.to_pickle('data/key_label_val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
